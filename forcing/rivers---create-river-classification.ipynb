{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain dimensions\n",
    "imin, imax = 1479, 2179\n",
    "jmin, jmax = 159, 799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ANHA12 runoff file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load structure from sample dataset of river runoff used in ANHA12\n",
    "# from Paul Myers' group (http://knossos.eas.ualberta.ca/anha/anhatable.php)\n",
    "c = nc.Dataset('/ocean/brogalla/GEOTRACES/data/runoff/ANHA12_runoff_monthly_combined_Dai_Trenberth_Bamber_y2015.nc','r')\n",
    "lon_rf  = np.array(c.variables['nav_lon'])\n",
    "lat_rf  = np.array(c.variables['nav_lat'])\n",
    "socoefr = np.array(c.variables['socoefr'])\n",
    "rf      = np.array(c.variables['runoff'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf[rf == 0] = np.nan\n",
    "lon_rf[rf == 0.0] = np.nan\n",
    "lat_rf[rf == 0.0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class numbers:\n",
    "1. Glaciers\n",
    "2. Continental\n",
    "3. Mines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All other small rivers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_river = np.empty(rf.shape)\n",
    "class_river[:] = np.nan\n",
    "class_river[~np.isnan(rf)] = 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glacial rivers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array of indices where latitude  & longitude condition (Greenland) is met\n",
    "index1 = np.argwhere((lat_rf < 82) & (lat_rf > 73) & (lon_rf < -62) & (lon_rf > -74))\n",
    "index2 = np.argwhere((lat_rf < 85) & (lat_rf > 76) & (lon_rf < -75) & (lon_rf > -85))\n",
    "index3 = np.argwhere((lat_rf < 74) & (lat_rf > 71) & (lon_rf < -70) & (lon_rf > -83))\n",
    "index4 = np.argwhere((lat_rf < 77) & (lat_rf > 73) & (lon_rf < -79) & (lon_rf > -84))\n",
    "index5 = np.argwhere((lat_rf < 80) & (lat_rf > 78) & (lon_rf < -90) & (lon_rf > -93))\n",
    "index6 = np.argwhere((lat_rf < 84) & (lat_rf > 79) & (lon_rf < -93) & (lon_rf > -97))\n",
    "index7 = np.argwhere((lat_rf < 86) & (lat_rf > 73) & (lon_rf < -40) & (lon_rf > -62))\n",
    "\n",
    "index8 = np.argwhere((lat_rf < 86) & (lat_rf > 55) & (lon_rf < 20) & (lon_rf > -62))\n",
    "index9 = np.argwhere((lat_rf < 75) & (lat_rf > 63) & (lon_rf < -50) & (lon_rf > -71))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_glacier(index, rf, class_river):\n",
    "    for i in range(0,index.shape[0]):         \n",
    "        if ~np.isnan(rf[index[i][0],index[i][1]]):\n",
    "#             rf[index[i][0],index[i][1]] = 1.0\n",
    "            class_river[index[i][0],index[i][1]] = 1.0\n",
    "    return class_river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_river = classify_glacier(index1, rf, class_river) #Greenland\n",
    "class_river = classify_glacier(index2, rf, class_river) #Ellesmere Island\n",
    "class_river = classify_glacier(index3, rf, class_river) #Baffin Island\n",
    "class_river = classify_glacier(index4, rf, class_river) #Southern Ellesmere Island\n",
    "class_river = classify_glacier(index5, rf, class_river) #Western Ellesmere Island\n",
    "class_river = classify_glacier(index6, rf, class_river) #Western Ellesmere Island\n",
    "class_river = classify_glacier(index7, rf, class_river) #More of Greenland\n",
    "class_river = classify_glacier(index8, rf, class_river) #S Greenland\n",
    "class_river = classify_glacier(index9, rf, class_river) #S Baffin Island"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continental drainage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_continental(index, rf, class_river):\n",
    "    for i in range(0,index.shape[0]):         \n",
    "        if ~np.isnan(rf[index[i][0],index[i][1]]):\n",
    "#             rf[index[i][0],index[i][1]] = 2.0\n",
    "            class_river[index[i][0],index[i][1]] = 2.0\n",
    "    return class_river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array of indices where latitude  & longitude condition (Greenland) is met\n",
    "index1 = np.argwhere((lat_rf < 71) & (lat_rf > 67) & (lon_rf < -118) & (lon_rf > -150))\n",
    "index2 = np.argwhere((lat_rf < 68) & (lat_rf > 67) & (lon_rf < -95) & (lon_rf > -115))\n",
    "index3 = np.argwhere((lat_rf < 70) & (lat_rf > 67) & (lon_rf < -88) & (lon_rf > -100))\n",
    "index4 = np.argwhere((lat_rf < 70) & (lat_rf > 65) & (lon_rf < -81) & (lon_rf > -87))\n",
    "index5 = np.argwhere((lat_rf < 69) & (lat_rf > 65) & (lon_rf < -80) & (lon_rf > -95))\n",
    "index6 = np.argwhere((lat_rf < 69) & (lat_rf > 67) & (lon_rf < -104) & (lon_rf > -109))\n",
    "index7 = np.argwhere((lat_rf < 69) & (lat_rf > 68) & (lon_rf < -116) & (lon_rf > -119))\n",
    "index8 = np.argwhere((lat_rf < 69.2) & (lat_rf > 68) & (lon_rf < -113) & (lon_rf > -116))\n",
    "\n",
    "index9 = np.argwhere((lat_rf < 62) & (lon_rf > -100) & (lon_rf < -50))\n",
    "index10 = np.argwhere((lat_rf < 68) & (lat_rf > 60) & (lon_rf > -130) & (lon_rf < -88))\n",
    "index11 = np.argwhere((lat_rf < 65) & (lat_rf > 64) & (lon_rf > -88) & (lon_rf < -87))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_river = classify_continental(index1, rf, class_river) \n",
    "class_river = classify_continental(index2, rf, class_river)\n",
    "class_river = classify_continental(index3, rf, class_river)\n",
    "class_river = classify_continental(index4, rf, class_river)\n",
    "class_river = classify_continental(index5, rf, class_river)\n",
    "class_river = classify_continental(index6, rf, class_river)\n",
    "class_river = classify_continental(index7, rf, class_river)\n",
    "class_river = classify_continental(index8, rf, class_river)\n",
    "class_river = classify_continental(index9, rf, class_river)\n",
    "class_river = classify_continental(index10, rf, class_river)\n",
    "class_river = classify_continental(index11, rf, class_river)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_gulf(index, rf, class_river):\n",
    "    for i in range(0,index.shape[0]):         \n",
    "        if ~np.isnan(rf[index[i][0],index[i][1]]):\n",
    "            class_river[index[i][0],index[i][1]] = 4.0\n",
    "    return class_river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = np.argwhere((lat_rf < 70) & (lat_rf > 69) & (lon_rf > -97) & (lon_rf < -94))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_river = classify_gulf(index1, rf, class_river)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consistency check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18818,) (18818,)\n"
     ]
    }
   ],
   "source": [
    "print(rf[~np.isnan(rf)].shape, class_river[~np.isnan(class_river)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write classification to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the new NetCDF file:\n",
    "ncda = nc.Dataset('/ocean/brogalla/GEOTRACES/data/paper1-forcing-files/river_class_202005.nc', 'w', zlib=True)\n",
    "\n",
    "ncda.createDimension('x',len(c.dimensions['x']))\n",
    "ncda.createDimension('y',len(c.dimensions['y']))\n",
    "\n",
    "rclass = ncda.createVariable('rclass', 'int16', ('y','x'))\n",
    "rclass.units = 'river class from 1-3'\n",
    "rclass.long_name = 'river class'\n",
    "rclass[:] = class_river\n",
    "\n",
    "ncda.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

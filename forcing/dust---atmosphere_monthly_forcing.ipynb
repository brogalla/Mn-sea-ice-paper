{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create monthly CESM atmospheric deposition files\n",
    "\n",
    "NCAR CESM output:\n",
    "Community Earth System Model (Community Atmosphere Model - CAM https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1002/2013MS000279) output: https://www.earthsystemgrid.org/; CESM1 CAM5 BGC Large Ensemble Atmosphere Post Processed Data, Monthly Averages.\n",
    "\n",
    "Specific run output: https://www.earthsystemgrid.org/dataset/ucar.cgd.ccsm4.CESM_CAM5_BGC_LE.atm.proc.monthly_ave.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import datetime\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "import cmocean\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Mode MAM3 (https://www.geosci-model-dev.net/5/709/2012/):\n",
    "\n",
    "- a1 --- Aitken mode --- 0.015-0.053 μm\n",
    "- a2 --- Accumulation mode --- 0.058-0.27 μm\n",
    "- a3 --- Coarse mode --- 0.80-3.65 μm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh  = nc.Dataset('/ocean/brogalla/GEOTRACES/data/ANHA12/ANHA12_mesh1.nc')\n",
    "mlons = np.array(mesh.variables['nav_lon'])\n",
    "mlats = np.array(mesh.variables['nav_lat'])\n",
    "tmask = np.array(mesh.variables['tmask'])[0,:,:,:]\n",
    "Z_masked = np.ma.masked_where((tmask > 0.1) , tmask) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_np(nav_lon, nav_lat, var_in, lon_ANHA12, lat_ANHA12):\n",
    "    # Interpolate some field to ANHA12 grid.\n",
    "    \n",
    "    from scipy.interpolate import griddata\n",
    "    LatLonPair = (nav_lon.flatten(), nav_lat.flatten())\n",
    "    a = nav_lon.flatten()\n",
    "    b = nav_lat.flatten()\n",
    "    c = var_in.flatten()\n",
    "\n",
    "    var_out = griddata(LatLonPair, var_in.flatten(), (lon_ANHA12, lat_ANHA12), method='linear')\n",
    "    # Take nearest neighbour interpolation to fill nans\n",
    "    var_fill = griddata(LatLonPair, var_in.flatten(), (lon_ANHA12, lat_ANHA12), method='nearest')\n",
    "    \n",
    "    var_out[np.isnan(var_out)] = var_fill[np.isnan(var_out)]\n",
    "    return var_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(filename, field1, field2):\n",
    "    # Save forcing field to file\n",
    "    \n",
    "    ncd = nc.Dataset(filename, 'w', zlib=True)\n",
    "    ncd.createDimension('x',len(mesh.dimensions['x']))\n",
    "    ncd.createDimension('y',len(mesh.dimensions['y']))\n",
    "    ncd.createDimension('time_counter',None)\n",
    "    \n",
    "    # variables\n",
    "    fine_dust             = ncd.createVariable('fdust', 'float64', ('y','x'))\n",
    "    fine_dust.units       = 'kg/m2/s'\n",
    "    fine_dust.long_name   = 'Fine dust deposition flux'  \n",
    "    fine_dust.coordinates = 'nav_lon nav_lat'\n",
    "    fine_dust[:]          = field1\n",
    "    \n",
    "    coarse_dust             = ncd.createVariable('cdust', 'float64', ('y','x'))\n",
    "    coarse_dust.units       = 'kg/m2/s'\n",
    "    coarse_dust.long_name   = 'Coarse dust deposition flux'  \n",
    "    coarse_dust.coordinates = 'nav_lon nav_lat'\n",
    "    coarse_dust[:]          = field2\n",
    "    \n",
    "    print('saved ', filename)\n",
    "\n",
    "    ncd.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Load NCAR dust flux files, zero negative depositional fluxes, and shift longitudes so that they wrap.\n",
    "    folder = '/ocean/brogalla/GEOTRACES/data/NCAR/'\n",
    "\n",
    "    dst_a1D = nc.Dataset(f'{folder}merged_dst_a1DDF.nc')\n",
    "    dst_a1S = nc.Dataset(f'{folder}merged_dst_a1SFWET.nc')\n",
    "    dst_a3D = nc.Dataset(f'{folder}merged_dst_a3DDF.nc')\n",
    "    dst_a3S = nc.Dataset(f'{folder}merged_dst_a3SFWET.nc')\n",
    "    \n",
    "    dst_a1DDF   = np.array(dst_a1D.variables['dst_a1DDF'])\n",
    "    dst_a1SFWET = np.array(dst_a1S.variables['dst_a1SFWET'])\n",
    "    dst_a3DDF   = np.array(dst_a3D.variables['dst_a3DDF'])\n",
    "    dst_a3SFWET = np.array(dst_a3S.variables['dst_a3SFWET'])\n",
    "    \n",
    "    # zero negative deposition fluxes:\n",
    "    dst_a1DDF[dst_a1DDF < 0]     = 0\n",
    "    dst_a1SFWET[dst_a1SFWET < 0] = 0\n",
    "    dst_a3DDF[dst_a3DDF < 0]     = 0\n",
    "    dst_a3SFWET[dst_a3SFWET < 0] = 0\n",
    "    lon  = dst_a1D.variables['lon']\n",
    "    lat  = dst_a1D.variables['lat']\n",
    "    date = dst_a1D.variables['date']\n",
    "    \n",
    "    lon = np.array(lon)\n",
    "    for i in range(0,len(lon)):\n",
    "        if lon[i] >= 180:\n",
    "            lon[i] = -360+lon[i]\n",
    "            \n",
    "    # change lons and lats array dimensions: (192x288)\n",
    "    lons, lats = np.meshgrid(lon,lat)    \n",
    "    dst_a1 = np.add(dst_a1DDF[:,:,:], dst_a1SFWET[:,:,:])\n",
    "    dst_a3 = np.add(dst_a3DDF[:,:,:], dst_a3SFWET[:,:,:])\n",
    "    \n",
    "    return date, lons, lats, dst_a1, dst_a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dates(file_year):\n",
    "    # Find file indices associated with the dates we want to use for the forcing files\n",
    "    file_date_start = file_year*10000 + 101\n",
    "    file_date_end = file_year*10000 + 1201\n",
    "    \n",
    "    start_index = []\n",
    "    end_index = []\n",
    "\n",
    "    for i in range(0,len(date)):\n",
    "        if date[i] == file_date_start:\n",
    "            start_index = i\n",
    "        elif date[i] == file_date_end:\n",
    "            end_index = i\n",
    "    \n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_ANHA12(file_year, savefiles=False):\n",
    "    # Interpolate NCAR fields to ANHA12 grid\n",
    "    \n",
    "    si, ei = find_dates(file_year)\n",
    "    dusta1 = dust_a1[si:ei+1,:,:]\n",
    "    dusta3 = dust_a3[si:ei+1,:,:]\n",
    "    print('Check that output is of the correct dimensions: ', dusta1.shape, dusta3.shape)\n",
    "    \n",
    "    interp_dst_a1 = np.empty((12, 2400, 1632))\n",
    "    interp_dst_a3 = np.empty((12, 2400, 1632))\n",
    "\n",
    "    # loop over the months:\n",
    "    for i in range(0,12):\n",
    "        interp_dst_a1[i,:,:] = interp_np(lons, lats, dusta1[i,:,:], mlons, mlats)\n",
    "        interp_dst_a3[i,:,:] = interp_np(lons, lats, dusta3[i,:,:], mlons, mlats)\n",
    "        \n",
    "    if savefiles:\n",
    "        location = '/ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/'\n",
    "        \n",
    "        for i in range(1,13):\n",
    "            save_file(f'{location}atm_flux_y{file_year}m{i:02}.nc',interp_dst_a1[i-1,:,:],\\\n",
    "                          interp_dst_a3[i-1,:,:])    \n",
    "    \n",
    "    return interp_dst_a1, interp_dst_a3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate to ANHA12 grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date, lons, lats, dust_a1, dust_a3 = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "Check that output is of the correct dimensions:  (12, 192, 288) (12, 192, 288) (12, 192, 288)\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m01.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m02.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m03.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m04.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m05.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m06.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m07.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m08.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m09.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m10.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m11.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/atm_flux_y2020m12.nc\n"
     ]
    }
   ],
   "source": [
    "for year in np.arange(2020,2021,1):\n",
    "    print(year)\n",
    "    interp_dst_a1, interp_dst_a3 = data_to_ANHA12(year, savefiles=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Monthly CESM ice flux files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import datetime\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "import cmocean\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh     = nc.Dataset('/ocean/brogalla/GEOTRACES/data/ANHA12/ANHA12_mesh1.nc')\n",
    "mlons    = np.array(mesh.variables['nav_lon'])\n",
    "mlats    = np.array(mesh.variables['nav_lat'])\n",
    "tmask    = np.array(mesh.variables['tmask'])[0,:,:,:] \n",
    "Z_masked = np.ma.masked_where((tmask > 0.1), tmask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sea ice dust forcing file from NCAR: \n",
    "# Run ID: https://www.earthsystemgrid.org/dataset/ucar.cgd.ccsm4.CESM_CAM5_BGC_LE.ice.proc.monthly_ave.faero_ocn003.html\n",
    "folder      = '/ocean/brogalla/GEOTRACES/data/NCAR/'\n",
    "faero_003_n = nc.Dataset(f'{folder}merged_faero_ocn003_nh.nc') #dust\n",
    "ocn003      = np.array(faero_003_n.variables['faero_ocn003'])\n",
    "time        = faero_003_n.variables['time']\n",
    "lons        = np.array(faero_003_n.variables['TLON'])\n",
    "lats        = np.array(faero_003_n.variables['TLAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap longitudes from -180 to +180 instead of 0 to 360\n",
    "for i in range(0,lons.shape[0]):\n",
    "    for j in range(0,lons.shape[1]):\n",
    "        if lons[i,j] >= 180:\n",
    "            lons[i,j] = -360+lons[i,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(filename, field1):\n",
    "    # Save forcing field to file:\n",
    "    ncd = nc.Dataset(filename, 'w', zlib=True)\n",
    "    \n",
    "    ncd.createDimension('x',len(mesh.dimensions['x']))\n",
    "    ncd.createDimension('y',len(mesh.dimensions['y']))\n",
    "    ncd.createDimension('time_counter',None)\n",
    "    \n",
    "    # variables\n",
    "    dust             = ncd.createVariable('dust', 'float64', ('y','x'))\n",
    "    dust.units       = 'kg/m2 s'\n",
    "    dust.long_name   = 'Dust deposition flux'  \n",
    "    dust.coordinates = 'nav_lon nav_lat'\n",
    "    dust[:]          = field1[:]\n",
    "    \n",
    "    print('saved ', filename)\n",
    "\n",
    "    ncd.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_np(nav_lon, nav_lat, var_in, lon_ANHA12, lat_ANHA12):\n",
    "    # Interpolate some field to ANHA12 grid.\n",
    "    \n",
    "    from scipy.interpolate import griddata\n",
    "    LatLonPair = (nav_lon, nav_lat)\n",
    "    var_out = griddata(LatLonPair, var_in, (lon_ANHA12, lat_ANHA12), method='linear')\n",
    "    # Take nearest neighbour interpolation to fill nans\n",
    "    var_fill = griddata(LatLonPair, var_in, (lon_ANHA12, lat_ANHA12), method='nearest')\n",
    "    \n",
    "    var_out[np.isnan(var_out)] = var_fill[np.isnan(var_out)]\n",
    "    return var_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dates(file_year, time):\n",
    "    file_date_start = file_year*365\n",
    "    file_date_end = (file_year+1)*365\n",
    "    \n",
    "    start_index = []\n",
    "    end_index = []\n",
    "\n",
    "    for i in range(0,len(time)):\n",
    "        if time[i] == file_date_start:\n",
    "            start_index = i\n",
    "        elif time[i] == file_date_end:\n",
    "            end_index = i\n",
    "\n",
    "#     print('start index: ', start_index)\n",
    "#     print('end index: ', end_index)\n",
    "    \n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_ANHA12(file_year, time, lons, lats, ocn003_masked, savefiles=False):\n",
    "    \n",
    "    start_index, end_index = find_dates(file_year, time)\n",
    "    \n",
    "    interp_dst = np.empty((12, 2400, 1632))\n",
    "\n",
    "    # loop over the months:\n",
    "    for i in range(0,12):\n",
    "        filt_ocn003 = ocn003_masked[start_index+i,:,:][~ocn003_masked[start_index+i,:,:].mask].data\n",
    "        filt_lons3 = lons[~ocn003_masked[start_index+i,:,:].mask].data\n",
    "        filt_lats3 = lats[~ocn003_masked[start_index+i,:,:].mask].data\n",
    "\n",
    "        interp_dst[i,:,:] = interp_np(filt_lons3, filt_lats3, filt_ocn003, mlons, mlats)\n",
    "        \n",
    "    if savefiles:\n",
    "        location='/ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/'\n",
    "        \n",
    "        for i in range(1,13):\n",
    "            save_file(f'{location}ice_flux_y{file_year}m{i:02}.nc',interp_dst[i-1,:,:])\n",
    "    \n",
    "    return interp_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocn003_masked = np.ma.masked_where((ocn003 >= 1e30), ocn003) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m01.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m02.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m03.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m04.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m05.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m06.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m07.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m08.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m09.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m10.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m11.nc\n",
      "saved  /ocean/brogalla/GEOTRACES/data/paper1-forcing-files/atmospheric/ice_flux_y2002m12.nc\n"
     ]
    }
   ],
   "source": [
    "for year in np.arange(2002,2003,1):\n",
    "    print(year)\n",
    "    interp_dst = data_to_ANHA12(year, time, lons, lats, ocn003_masked, savefiles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
